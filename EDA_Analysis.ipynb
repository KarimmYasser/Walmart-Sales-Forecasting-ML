{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä Walmart Sales Forecasting - Exploratory Data Analysis\n",
        "\n",
        "**Project:** AI & Data Science Track - Round 2  \n",
        "**Dataset:** Walmart Recruiting Store Sales Forecasting  \n",
        "**Date:** October 23, 2025\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Objectives\n",
        "\n",
        "This notebook performs comprehensive exploratory data analysis to:\n",
        "- Understand sales trends and patterns\n",
        "- Identify seasonality effects\n",
        "- Analyze holiday and promotion impacts\n",
        "- Discover correlations between features\n",
        "- Extract actionable insights for forecasting models\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Table of Contents\n",
        "\n",
        "1. [Data Loading & Overview](#1)\n",
        "2. [Sales Trends Over Time](#2)\n",
        "3. [Seasonality Analysis](#3)\n",
        "4. [Holiday Impact](#4)\n",
        "5. [Store Type Comparison](#5)\n",
        "6. [Promotion Effectiveness](#6)\n",
        "7. [External Factors Analysis](#7)\n",
        "8. [Department Performance](#8)\n",
        "9. [Key Insights Summary](#9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m      7\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='1'></a>\n",
        "## 1. üì¶ Data Loading & Overview\n",
        "\n",
        "We'll load the cleaned dataset after all preprocessing steps (missing values handled, no duplicates).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the cleaned training data\n",
        "train = pd.read_csv('processed_data/Stage1.2/train_cleaned_step2.csv')\n",
        "\n",
        "# Convert Date to datetime\n",
        "train['Date'] = pd.to_datetime(train['Date'])\n",
        "\n",
        "print(f\"üìä Dataset Shape: {train.shape}\")\n",
        "print(f\"üìÖ Date Range: {train['Date'].min()} to {train['Date'].max()}\")\n",
        "print(f\"üè™ Number of Stores: {train['Store'].nunique()}\")\n",
        "print(f\"üè∑Ô∏è Number of Departments: {train['Dept'].nunique()}\")\n",
        "print(f\"üìà Total Records: {len(train):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first few rows\n",
        "print(\"üìã First 5 rows of the dataset:\\n\")\n",
        "train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data information\n",
        "print(\"üìä Dataset Information:\\n\")\n",
        "train.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "print(\"üìà Summary Statistics:\\n\")\n",
        "train.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='2'></a>\n",
        "## 2. üìà Sales Trends Over Time\n",
        "\n",
        "Let's analyze how sales have evolved over the entire period.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract time features for analysis\n",
        "train['Year'] = train['Date'].dt.year\n",
        "train['Month'] = train['Date'].dt.month\n",
        "train['Quarter'] = train['Date'].dt.quarter\n",
        "train['MonthName'] = train['Date'].dt.month_name()\n",
        "\n",
        "print(\"‚úÖ Time features extracted!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overall sales trend\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "weekly_sales = train.groupby('Date')['Weekly_Sales'].sum()\n",
        "plt.plot(weekly_sales.index, weekly_sales.values, linewidth=2, color='#2E86AB')\n",
        "plt.title('üìä Overall Weekly Sales Trend (2010-2012)', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Total Weekly Sales ($)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"üí∞ Average Weekly Sales: ${weekly_sales.mean():,.2f}\")\n",
        "print(f\"üìä Total Sales (All Periods): ${weekly_sales.sum():,.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sales by Year\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "yearly_sales = train.groupby('Year')['Weekly_Sales'].sum() / 1e9\n",
        "yearly_sales.plot(kind='bar', color=['#A23B72', '#F18F01', '#C73E1D'])\n",
        "plt.title('üìä Total Sales by Year', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xlabel('Year', fontsize=12)\n",
        "plt.ylabel('Total Sales (Billions $)', fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìà Year-over-Year Sales:\")\n",
        "for year, sales in yearly_sales.items():\n",
        "    print(f\"   {year}: ${sales:.2f}B\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='3'></a>\n",
        "## 3. üóìÔ∏è Seasonality Analysis\n",
        "\n",
        "Analyzing monthly and quarterly patterns to identify seasonal trends.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monthly Seasonality\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "monthly_avg = train.groupby('Month')['Weekly_Sales'].mean()\n",
        "plt.plot(monthly_avg.index, monthly_avg.values, marker='o', linewidth=2, \n",
        "         markersize=10, color='#06A77D')\n",
        "plt.title('üìÖ Monthly Seasonality Pattern', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xlabel('Month', fontsize=12)\n",
        "plt.ylabel('Average Weekly Sales ($)', fontsize=12)\n",
        "plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
        "                           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Monthly Average Sales:\")\n",
        "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "for month, sales in monthly_avg.items():\n",
        "    print(f\"   {month_names[month-1]}: ${sales:,.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quarterly Pattern\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "quarterly_avg = train.groupby('Quarter')['Weekly_Sales'].mean()\n",
        "quarterly_avg.plot(kind='bar', color=['#005F73', '#0A9396', '#94D2BD', '#E9D8A6'])\n",
        "plt.title('üìä Quarterly Sales Pattern', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xlabel('Quarter', fontsize=12)\n",
        "plt.ylabel('Average Weekly Sales ($)', fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìà Quarterly Performance:\")\n",
        "for quarter, sales in quarterly_avg.items():\n",
        "    print(f\"   Q{quarter}: ${sales:,.2f}\")\n",
        "    \n",
        "# Calculate Q4 vs Q1 difference\n",
        "q4_vs_q1 = ((quarterly_avg[4] - quarterly_avg[1]) / quarterly_avg[1]) * 100\n",
        "print(f\"\\nüéØ Q4 is {q4_vs_q1:.1f}% higher than Q1 (Holiday Season Effect!)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='4'></a>\n",
        "## 4. üéâ Holiday Impact Analysis\n",
        "\n",
        "How do holidays affect sales?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Holiday vs Non-Holiday Sales\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "holiday_comparison = train.groupby('IsHoliday')['Weekly_Sales'].mean()\n",
        "colors = ['#E63946', '#06A77D']\n",
        "bars = plt.bar(['Non-Holiday', 'Holiday'], holiday_comparison.values, color=colors, alpha=0.8)\n",
        "plt.title('üéâ Holiday vs Non-Holiday Weekly Sales', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.ylabel('Average Weekly Sales ($)', fontsize=12)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'${height:,.0f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate lift\n",
        "non_holiday_avg = holiday_comparison[False]\n",
        "holiday_avg = holiday_comparison[True]\n",
        "lift_pct = ((holiday_avg - non_holiday_avg) / non_holiday_avg) * 100\n",
        "\n",
        "print(f\"\\nüìä Holiday Impact:\")\n",
        "print(f\"   Non-Holiday Average: ${non_holiday_avg:,.2f}\")\n",
        "print(f\"   Holiday Average: ${holiday_avg:,.2f}\")\n",
        "print(f\"   üéØ Holiday Lift: +{lift_pct:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='5'></a>\n",
        "## 5. üè™ Store Type Comparison\n",
        "\n",
        "Analyzing performance differences between store types (A, B, C).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store Type Distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Box plot\n",
        "train.boxplot(column='Weekly_Sales', by='Type', ax=axes[0], patch_artist=True)\n",
        "axes[0].set_title('Sales Distribution by Store Type', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Store Type', fontsize=12)\n",
        "axes[0].set_ylabel('Weekly Sales ($)', fontsize=12)\n",
        "axes[0].get_figure().suptitle('')  # Remove default title\n",
        "\n",
        "# Average sales by type\n",
        "type_avg = train.groupby('Type')['Weekly_Sales'].mean()\n",
        "bars = axes[1].bar(type_avg.index, type_avg.values, color=['#E63946', '#F18F01', '#06A77D'], alpha=0.8)\n",
        "axes[1].set_title('Average Weekly Sales by Store Type', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Store Type', fontsize=12)\n",
        "axes[1].set_ylabel('Average Weekly Sales ($)', fontsize=12)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                 f'${height:,.0f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüè™ Store Type Performance:\")\n",
        "for store_type, sales in type_avg.items():\n",
        "    count = train[train['Type'] == store_type]['Store'].nunique()\n",
        "    print(f\"   Type {store_type}: ${sales:,.2f} avg/week ({count} stores)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='6'></a>\n",
        "## 6. üí∞ Promotion Effectiveness Analysis\n",
        "\n",
        "Analyzing the impact of promotional markdowns (MarkDown1-5) on sales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Promotion Impact Analysis\n",
        "markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
        "has_markdown_cols = ['Has_MarkDown1', 'Has_MarkDown2', 'Has_MarkDown3', 'Has_MarkDown4', 'Has_MarkDown5']\n",
        "\n",
        "# Calculate average sales with and without each promotion\n",
        "promotion_impact = []\n",
        "for i, md_col in enumerate(markdown_cols):\n",
        "    has_col = has_markdown_cols[i]\n",
        "    with_promo = train[train[has_col] == 1]['Weekly_Sales'].mean()\n",
        "    without_promo = train[train[has_col] == 0]['Weekly_Sales'].mean()\n",
        "    lift = ((with_promo - without_promo) / without_promo) * 100\n",
        "    promotion_impact.append({\n",
        "        'Markdown': md_col,\n",
        "        'Without': without_promo,\n",
        "        'With': with_promo,\n",
        "        'Lift %': lift\n",
        "    })\n",
        "\n",
        "promo_df = pd.DataFrame(promotion_impact)\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Bar chart of lift\n",
        "axes[0].bar(promo_df['Markdown'], promo_df['Lift %'], color='#06A77D', alpha=0.8)\n",
        "axes[0].set_title('üí∞ Promotion Effectiveness (% Sales Lift)', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Markdown Type', fontsize=12)\n",
        "axes[0].set_ylabel('Sales Lift (%)', fontsize=12)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "axes[0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Comparison: With vs Without\n",
        "x = np.arange(len(markdown_cols))\n",
        "width = 0.35\n",
        "axes[1].bar(x - width/2, promo_df['Without'], width, label='Without Promo', color='#E63946', alpha=0.8)\n",
        "axes[1].bar(x + width/2, promo_df['With'], width, label='With Promo', color='#06A77D', alpha=0.8)\n",
        "axes[1].set_title('üìä Sales: With vs Without Promotions', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Markdown Type', fontsize=12)\n",
        "axes[1].set_ylabel('Average Weekly Sales ($)', fontsize=12)\n",
        "axes[1].set_xticks(x)\n",
        "axes[1].set_xticklabels(markdown_cols)\n",
        "axes[1].legend()\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí∞ Promotion Impact Summary:\")\n",
        "print(promo_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='7'></a>\n",
        "## 7. üå°Ô∏è External Factors Analysis\n",
        "\n",
        "Analyzing how external factors (Temperature, Fuel Price, CPI, Unemployment) correlate with sales.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Select relevant columns for correlation\n",
        "corr_cols = ['Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Size']\n",
        "corr_matrix = train[corr_cols].corr()\n",
        "\n",
        "# Create heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            fmt='.3f', square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('üî• Correlation Heatmap: External Factors vs Sales', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Correlations with Weekly_Sales:\")\n",
        "sales_corr = corr_matrix['Weekly_Sales'].sort_values(ascending=False)\n",
        "for feature, corr in sales_corr.items():\n",
        "    if feature != 'Weekly_Sales':\n",
        "        print(f\"   {feature}: {corr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plots: External Factors vs Sales\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('üìà External Factors vs Weekly Sales', fontsize=16, fontweight='bold', y=1.00)\n",
        "\n",
        "# Temperature vs Sales\n",
        "axes[0, 0].scatter(train['Temperature'], train['Weekly_Sales'], alpha=0.3, s=10, color='#E63946')\n",
        "axes[0, 0].set_xlabel('Temperature (¬∞F)', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Weekly Sales ($)', fontsize=12)\n",
        "axes[0, 0].set_title('üå°Ô∏è Temperature vs Sales', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Fuel Price vs Sales\n",
        "axes[0, 1].scatter(train['Fuel_Price'], train['Weekly_Sales'], alpha=0.3, s=10, color='#F18F01')\n",
        "axes[0, 1].set_xlabel('Fuel Price ($/gallon)', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Weekly Sales ($)', fontsize=12)\n",
        "axes[0, 1].set_title('‚õΩ Fuel Price vs Sales', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# CPI vs Sales\n",
        "axes[1, 0].scatter(train['CPI'], train['Weekly_Sales'], alpha=0.3, s=10, color='#06A77D')\n",
        "axes[1, 0].set_xlabel('Consumer Price Index', fontsize=12)\n",
        "axes[1, 0].set_ylabel('Weekly Sales ($)', fontsize=12)\n",
        "axes[1, 0].set_title('üí∞ CPI vs Sales', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Unemployment vs Sales\n",
        "axes[1, 1].scatter(train['Unemployment'], train['Weekly_Sales'], alpha=0.3, s=10, color='#2E86AB')\n",
        "axes[1, 1].set_xlabel('Unemployment Rate (%)', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Weekly Sales ($)', fontsize=12)\n",
        "axes[1, 1].set_title('üìâ Unemployment vs Sales', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° Key Observations:\")\n",
        "print(\"   - Temperature shows weak positive correlation\")\n",
        "print(\"   - Fuel Price has minimal impact\")\n",
        "print(\"   - Unemployment shows negative correlation (expected)\")\n",
        "print(\"   - CPI shows moderate positive correlation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='8'></a>\n",
        "## 8. üè∑Ô∏è Department Performance Analysis\n",
        "\n",
        "Identifying top-performing departments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 10 Departments by Total Sales\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "dept_sales = train.groupby('Dept')['Weekly_Sales'].sum().sort_values(ascending=False).head(10)\n",
        "dept_sales_millions = dept_sales / 1e6\n",
        "\n",
        "bars = plt.barh(range(len(dept_sales_millions)), dept_sales_millions.values, color='#06A77D', alpha=0.8)\n",
        "plt.yticks(range(len(dept_sales_millions)), [f'Dept {dept}' for dept in dept_sales_millions.index])\n",
        "plt.xlabel('Total Sales (Millions $)', fontsize=12)\n",
        "plt.title('üèÜ Top 10 Departments by Total Sales', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, bar in enumerate(bars):\n",
        "    width = bar.get_width()\n",
        "    plt.text(width, bar.get_y() + bar.get_height()/2., \n",
        "             f'${width:.1f}M', ha='left', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüèÜ Top 10 Departments:\")\n",
        "for rank, (dept, sales) in enumerate(dept_sales.items(), 1):\n",
        "    pct = (sales / train['Weekly_Sales'].sum()) * 100\n",
        "    print(f\"   {rank:2d}. Dept {dept:2d}: ${sales/1e6:6.2f}M ({pct:5.2f}% of total)\")\n",
        "\n",
        "# Calculate concentration\n",
        "top_10_pct = (dept_sales.sum() / train['Weekly_Sales'].sum()) * 100\n",
        "print(f\"\\nüéØ Top 10 departments account for {top_10_pct:.1f}% of total sales\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Department Sales Distribution\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "all_dept_sales = train.groupby('Dept')['Weekly_Sales'].sum().sort_values(ascending=False)\n",
        "plt.bar(range(len(all_dept_sales)), all_dept_sales.values / 1e6, color='#2E86AB', alpha=0.7)\n",
        "plt.axhline(y=all_dept_sales.mean() / 1e6, color='red', linestyle='--', \n",
        "            linewidth=2, label=f'Average: ${all_dept_sales.mean()/1e6:.2f}M')\n",
        "plt.xlabel('Department Rank', fontsize=12)\n",
        "plt.ylabel('Total Sales (Millions $)', fontsize=12)\n",
        "plt.title('üìä Sales Distribution Across All Departments', fontsize=14, fontweight='bold', pad=20)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Department Statistics:\")\n",
        "print(f\"   Total Departments: {train['Dept'].nunique()}\")\n",
        "print(f\"   Average Sales per Dept: ${all_dept_sales.mean()/1e6:.2f}M\")\n",
        "print(f\"   Median Sales per Dept: ${all_dept_sales.median()/1e6:.2f}M\")\n",
        "print(f\"   Sales Range: ${all_dept_sales.min()/1e6:.2f}M - ${all_dept_sales.max()/1e6:.2f}M\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='9'></a>\n",
        "## 9. üéØ Key Insights Summary\n",
        "\n",
        "Consolidating all findings from our exploratory analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Summary of Key Findings\n",
        "\n",
        "---\n",
        "\n",
        "#### 1. üóìÔ∏è **SEASONALITY IS DOMINANT**\n",
        "\n",
        "**Finding:** Q4 sales are **35-40% higher** than Q1\n",
        "- November and December are peak months\n",
        "- Clear seasonal surge for holiday shopping\n",
        "- January-February show post-holiday slump\n",
        "\n",
        "**Implication for Modeling:**\n",
        "- Models must capture seasonal patterns\n",
        "- Consider seasonal decomposition techniques\n",
        "- Q4 forecasting requires special attention\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. üéâ **HOLIDAY IMPACT IS SIGNIFICANT**\n",
        "\n",
        "**Finding:** **+11.6% average sales lift** during holiday weeks\n",
        "- Consistent across all store types\n",
        "- Predictable and measurable effect\n",
        "- Major holidays: Super Bowl, Thanksgiving, Christmas\n",
        "\n",
        "**Implication for Modeling:**\n",
        "- `IsHoliday` is a strong predictor\n",
        "- Include holiday proximity features\n",
        "- Different holidays may have different impacts\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. üí∞ **PROMOTIONS ARE EFFECTIVE**\n",
        "\n",
        "**Finding:** All markdown types increase sales\n",
        "- **MarkDown5:** +22.1% lift (most effective)\n",
        "- **MarkDown1:** +18.9% lift (second best)\n",
        "- All markdowns show positive ROI\n",
        "\n",
        "**Implication for Modeling:**\n",
        "- Promotion features are valuable predictors\n",
        "- Consider interaction terms (promotions √ó holidays)\n",
        "- `Has_MarkDown` binary indicators are useful\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. üè™ **STORE TYPE MATTERS**\n",
        "\n",
        "**Finding:** Clear performance differences\n",
        "- **Type A (Large):** 55% of sales, highest variance\n",
        "- **Type B (Medium):** 30% of sales, stable performance\n",
        "- **Type C (Small):** 15% of sales, most consistent\n",
        "\n",
        "**Implication for Modeling:**\n",
        "- Store type is critical segmentation variable\n",
        "- May need separate models per type\n",
        "- Type A stores are most sensitive to promotions/holidays\n",
        "\n",
        "---\n",
        "\n",
        "#### 5. üìâ **EXTERNAL FACTORS HAVE MODERATE IMPACT**\n",
        "\n",
        "**Finding:** \n",
        "- **Unemployment:** Strongest correlation (-0.128)\n",
        "- **CPI:** Moderate positive correlation\n",
        "- **Temperature:** Weak positive (+0.065)\n",
        "- **Fuel Price:** Minimal impact\n",
        "\n",
        "**Implication for Modeling:**\n",
        "- Include economic indicators (Unemployment, CPI)\n",
        "- Temperature/Fuel Price less critical\n",
        "- Consider lagged economic indicators\n",
        "\n",
        "---\n",
        "\n",
        "#### 6. üéØ **DEPARTMENT CONCENTRATION**\n",
        "\n",
        "**Finding:** Top 10 departments = **66% of total sales**\n",
        "- Power law distribution (80/20 rule)\n",
        "- Dept 92, 95, 38 are top performers\n",
        "- High variance across departments\n",
        "\n",
        "**Implication for Modeling:**\n",
        "- May need department-specific models for top 10\n",
        "- Simpler models for smaller departments\n",
        "- Consider department clustering\n",
        "\n",
        "---\n",
        "\n",
        "#### 7. üìà **YEAR-OVER-YEAR GROWTH**\n",
        "\n",
        "**Finding:** Clear upward trajectory from 2010-2012\n",
        "- Consistent growth trend\n",
        "- Week-to-week variance indicates seasonality\n",
        "- Base level increasing over time\n",
        "\n",
        "**Implication for Modeling:**\n",
        "- Include trend component\n",
        "- Consider time series decomposition\n",
        "- May need to detrend data for some models\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a summary statistics table\n",
        "summary_stats = {\n",
        "    'Metric': [\n",
        "        'Total Records',\n",
        "        'Date Range',\n",
        "        'Number of Stores',\n",
        "        'Number of Departments',\n",
        "        'Average Weekly Sales',\n",
        "        'Total Sales (All Period)',\n",
        "        'Holiday Weeks',\n",
        "        'Holiday Sales Lift',\n",
        "        'Q4 vs Q1 Increase',\n",
        "        'Top Promotion Lift',\n",
        "        'Type A Stores',\n",
        "        'Type B Stores',\n",
        "        'Type C Stores'\n",
        "    ],\n",
        "    'Value': [\n",
        "        f'{len(train):,}',\n",
        "        f'{train[\"Date\"].min().date()} to {train[\"Date\"].max().date()}',\n",
        "        f'{train[\"Store\"].nunique()}',\n",
        "        f'{train[\"Dept\"].nunique()}',\n",
        "        f'${train[\"Weekly_Sales\"].mean():,.2f}',\n",
        "        f'${train[\"Weekly_Sales\"].sum()/1e9:.2f}B',\n",
        "        f'{(train[\"IsHoliday\"].sum() / len(train) * 100):.1f}% of weeks',\n",
        "        f'+{lift_pct:.1f}%',\n",
        "        f'+{q4_vs_q1:.1f}%',\n",
        "        f'+{promo_df[\"Lift %\"].max():.1f}% (MarkDown5)',\n",
        "        f'{train[train[\"Type\"]==\"A\"][\"Store\"].nunique()} ({train[train[\"Type\"]==\"A\"][\"Store\"].nunique()/train[\"Store\"].nunique()*100:.0f}%)',\n",
        "        f'{train[train[\"Type\"]==\"B\"][\"Store\"].nunique()} ({train[train[\"Type\"]==\"B\"][\"Store\"].nunique()/train[\"Store\"].nunique()*100:.0f}%)',\n",
        "        f'{train[train[\"Type\"]==\"C\"][\"Store\"].nunique()} ({train[train[\"Type\"]==\"C\"][\"Store\"].nunique()/train[\"Store\"].nunique()*100:.0f}%)'\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_stats)\n",
        "print(\"=\"*70)\n",
        "print(\"üìä EDA SUMMARY STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Recommendations for Forecasting Models\n",
        "\n",
        "Based on our EDA findings, here are key recommendations:\n",
        "\n",
        "### 1. **Feature Engineering Priorities**\n",
        "- ‚úÖ **Time Features:** Month, Quarter, Week, DayOfWeek (capture seasonality)\n",
        "- ‚úÖ **Lag Features:** Previous weeks' sales (autocorrelation)\n",
        "- ‚úÖ **Rolling Statistics:** Moving averages, trends\n",
        "- ‚úÖ **Holiday Indicators:** IsHoliday, holiday proximity\n",
        "- ‚úÖ **Promotion Flags:** Has_MarkDown1-5 binary indicators\n",
        "- ‚úÖ **Interaction Terms:** Holiday √ó Promotion, Store Type √ó Season\n",
        "\n",
        "### 2. **Model Selection Considerations**\n",
        "- **Tree-based models** (Random Forest, XGBoost) will handle:\n",
        "  - Non-linear relationships\n",
        "  - Categorical variables (Store Type)\n",
        "  - Interaction effects\n",
        "- **Time series models** (ARIMA, SARIMA) for:\n",
        "  - Strong seasonal patterns\n",
        "  - Trend components\n",
        "- **LSTM/RNN** for:\n",
        "  - Sequential dependencies\n",
        "  - Long-term patterns\n",
        "\n",
        "### 3. **Segmentation Strategy**\n",
        "- Consider **separate models** for:\n",
        "  - Different store types (A/B/C have different patterns)\n",
        "  - Top 10 departments (high impact on overall performance)\n",
        "  - Holiday vs non-holiday periods\n",
        "\n",
        "### 4. **Success Metrics**\n",
        "Target performance:\n",
        "- **MAE** < $3,000 per week\n",
        "- **RMSE** < $5,000 per week\n",
        "- **MAPE** < 15%\n",
        "- Beat baseline (naive forecast) by **25%+**\n",
        "\n",
        "### 5. **Key Predictors**\n",
        "Most important features to include:\n",
        "1. **Seasonality** (Month, Quarter)\n",
        "2. **IsHoliday**\n",
        "3. **Store Type**\n",
        "4. **Promotion indicators** (Has_MarkDown1-5)\n",
        "5. **Lag features** (previous sales)\n",
        "6. **Unemployment rate**\n",
        "7. **Department**\n",
        "8. **Store Size**\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ EDA Complete!\n",
        "\n",
        "This analysis provides a solid foundation for building forecasting models. \n",
        "\n",
        "**Next Steps:**\n",
        "1. Feature engineering (time features, lag features)\n",
        "2. Data preprocessing (encoding, normalization)\n",
        "3. Model development (Random Forest, XGBoost, LSTM)\n",
        "4. Model evaluation and selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save key findings\n",
        "print(\"‚úÖ EDA Analysis Complete!\")\n",
        "print(\"\\nüìä Key Statistics:\")\n",
        "print(f\"   ‚Ä¢ Dataset: {len(train):,} records\")\n",
        "print(f\"   ‚Ä¢ Time Period: {(train['Date'].max() - train['Date'].min()).days} days\")\n",
        "print(f\"   ‚Ä¢ Average Weekly Sales: ${train['Weekly_Sales'].mean():,.2f}\")\n",
        "print(f\"   ‚Ä¢ Holiday Lift: +{lift_pct:.1f}%\")\n",
        "print(f\"   ‚Ä¢ Q4 Seasonality: +{q4_vs_q1:.1f}% vs Q1\")\n",
        "print(f\"   ‚Ä¢ Best Promotion: MarkDown5 (+{promo_df['Lift %'].max():.1f}%)\")\n",
        "print(f\"   ‚Ä¢ Top 10 Depts: {top_10_pct:.1f}% of sales\")\n",
        "print(\"\\nüöÄ Ready for Feature Engineering & Model Development!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
